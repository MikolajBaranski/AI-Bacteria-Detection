{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c7100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d9d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('runs/detect/train8/weights/best.pt')\n",
    "set = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ffd06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_objects_in_label_file(label_file):\n",
    "    try:\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Remove comments and empty lines\n",
    "        lines = [line.strip() for line in lines if line.strip() and not line.strip().startswith('#')]\n",
    "        \n",
    "        # Count the number of lines (objects)\n",
    "        num_objects = len(lines)\n",
    "        \n",
    "        return num_objects\n",
    "    except Exception as e:\n",
    "        print(f\"Error counting objects in label file: {e}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5293e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get folder\n",
    "train_image_folder = f\"/home/ucloud/data_yolo/images/train\"\n",
    "train_labels_folder = f\"/home/ucloud/data_yolo/labels/train\"\n",
    "\n",
    "val_image_folder = f\"/home/ucloud/data_yolo/images/val\"\n",
    "val_labels_folder = f\"/home/ucloud/data_yolo/labels/val\"\n",
    "\n",
    "# Ids\n",
    "train_ids_path = '/home/ucloud/train.txt'\n",
    "val_ids_path = '/home/ucloud/validation.txt'\n",
    "\n",
    "# Train\n",
    "with open(train_ids_path, 'r') as file:\n",
    "    train_ids = [line.strip() for line in file]\n",
    "# Val\n",
    "with open(val_ids_path, 'r') as file:\n",
    "    val_ids = [line.strip() for line in file]\n",
    "    \n",
    "train_image_paths = [os.path.join(train_image_folder, f\"{id}.jpg\") for id in train_ids]\n",
    "val_image_paths = [os.path.join(val_image_folder, f\"{id}.jpg\") for id in val_ids]\n",
    "\n",
    "train_label_paths = [os.path.join(train_labels_folder, f\"{id}.txt\") for id in train_ids]\n",
    "val_label_paths = [os.path.join(val_labels_folder, f\"{id}.txt\") for id in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec299850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path\n",
    "\n",
    "if set == 'train':\n",
    "    images_path = train_image_paths\n",
    "    labels_path = train_label_paths\n",
    "elif set == 'val':\n",
    "    images_path = val_image_paths\n",
    "    labels_path = val_label_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15f4fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming images_path is a list of image paths\n",
    "batch_size = 20\n",
    "\n",
    "true_num = []\n",
    "pred_num = []\n",
    "\n",
    "# Calculate the total number of batches\n",
    "num_batches = (len(images_path) + batch_size - 1) // batch_size\n",
    "\n",
    "# Process images in batches\n",
    "for batch_idx in tqdm(range(num_batches), desc='Processing Batches'):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min((batch_idx + 1) * batch_size, len(images_path))\n",
    "    batch_images_path = images_path[start_idx:end_idx]\n",
    "    batch_label_path = labels_path[start_idx:end_idx]\n",
    "\n",
    "    # Process the current batch\n",
    "    batch_results = []\n",
    "    for image_path in batch_images_path:\n",
    "        result = model(image_path)\n",
    "        batch_results.append(len(result[0].boxes.cls))\n",
    "    pred_num.extend(batch_results)\n",
    "    \n",
    "    batch_results = []\n",
    "    for label_path in batch_label_path:\n",
    "        result = count_objects_in_label_file(label_path)\n",
    "        batch_results.append(result)\n",
    "    true_num.extend(batch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a402b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, mean_squared_log_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4373033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels= true_num\n",
    "predicted_labels = pred_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6198422",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy multi-labal:\", accuracy_score(true_labels, predicted_labels))\n",
    "print(\"Mean Squared Logarithmic Error:\", mean_squared_log_error(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeb549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram plot using seaborn\n",
    "sns.histplot([x for x in true_labels if x != 0], bins=50, kde=True)  # Adjust the number of bins as needed\n",
    "plt.title('Histogram Plot')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705baa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram plot using seaborn\n",
    "sns.histplot([x for x in predicted_labels if x != 0], bins=50, kde=True)  # Adjust the number of bins as needed\n",
    "plt.title('Histogram Plot')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bd322f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(true_labels, predicted_labels, color='blue', alpha=0.5)  # Adjust alpha for transparency\n",
    "plt.title('Scatter Plot of Predicted vs. True Labels')\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b3ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a violin plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(data=[true_labels, predicted_labels], palette=['blue', 'red'])\n",
    "plt.title('Violin Plot of Predicted vs. True Labels')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dac6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_binary = [0 if label == 0 else 1 for label in true_labels]\n",
    "predicted_labels_binary = [0 if label == 0 else 1 for label in predicted_labels]\n",
    "\n",
    "accuracy = accuracy_score(true_labels_binary, predicted_labels_binary)\n",
    "precision = precision_score(true_labels_binary, predicted_labels_binary)\n",
    "recall = recall_score(true_labels_binary, predicted_labels_binary)\n",
    "f1 = f1_score(true_labels_binary, predicted_labels_binary)\n",
    "cm = confusion_matrix(true_labels_binary, predicted_labels_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ddc17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class labels\n",
    "classes = ['Empty', 'Contaminated']\n",
    "conf_matrix = cm\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "# Add colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# Add tick marks and labels\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "# Add text annotations\n",
    "thresh = conf_matrix.max() / 2.\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, format(conf_matrix[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb4a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018295ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my_env] *",
   "language": "python",
   "name": "conda-env-my_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
